---
description: Python coding standards for DRY, mypy-compatible, Pydantic-based code with proper formatting
globs:
  - "**/*.py"
alwaysApply: true
---

# üêç **PYTHON CODING STANDARDS**

## üéØ **CORE PRINCIPLES**
- **DRY (Don't Repeat Yourself)**: Eliminate code duplication through abstraction and reuse
- **Type Safety**: Full mypy compatibility with comprehensive type annotations
- **Data Validation**: Use Pydantic models for all data structures and validation
- **Code Quality**: Format with black, lint with flake8, type-check with mypy
- **Modern Python**: Use Python 3.11+ features and best practices

## üìù **CODE FORMATTING REQUIREMENTS**

### **MANDATORY FORMATTING STEPS:**
1. **ALWAYS** run `make format` before claiming work is complete
2. **ALWAYS** run `make lint` to check for style issues
3. **ALWAYS** run `make mypy` to verify type safety
4. **NEVER** submit unformatted code
5. **NEVER** ignore linting warnings or errors

### **Formatting Tools:**
- **Black**: Code formatting (line length: 88 characters)
- **Flake8**: Linting with custom rules for this project
- **MyPy**: Static type checking with strict mode
- **isort**: Import sorting (handled by black)

## üîÑ **DRY (DON'T REPEAT YOURSELF) PRINCIPLES**

### **Code Reuse Requirements:**
- **ALWAYS** extract common functionality into reusable functions/classes
- **ALWAYS** use inheritance and composition to avoid duplication
- **ALWAYS** create utility functions for repeated logic
- **ALWAYS** use decorators for cross-cutting concerns
- **NEVER** copy-paste code blocks
- **NEVER** duplicate validation logic
- **NEVER** repeat configuration patterns

### **DRY Implementation Patterns:**
```python
# ‚úÖ GOOD: Reusable base class
class BaseMatcher(ABC):
    @abstractmethod
    def match(self, query: str, identifiers: List[str]) -> List[MatchResult]:
        pass

# ‚úÖ GOOD: Utility function
def validate_threshold(value: float) -> float:
    if not 0.0 <= value <= 1.0:
        raise ValueError(f"Threshold must be between 0.0 and 1.0, got {value}")
    return value

# ‚ùå BAD: Repeated validation logic
def fuzzy_search(self, query: str) -> List[MatchResult]:
    if not 0.0 <= self.threshold <= 1.0:  # Duplicated
        raise ValueError("Invalid threshold")
    # ...

def semantic_search(self, query: str) -> List[MatchResult]:
    if not 0.0 <= self.threshold <= 1.0:  # Duplicated
        raise ValueError("Invalid threshold")
    # ...
```

## üè∑Ô∏è **TYPE ANNOTATIONS & MYPY COMPATIBILITY**

### **Type Annotation Requirements:**
- **ALWAYS** annotate function parameters and return types
- **ALWAYS** annotate class attributes
- **ALWAYS** use `from __future__ import annotations` for forward references
- **ALWAYS** use `typing` module for complex types
- **ALWAYS** use `typing_extensions` for newer type features
- **NEVER** use `Any` without explicit justification
- **NEVER** ignore mypy errors

### **Type Annotation Examples:**
```python
from __future__ import annotations
from typing import List, Dict, Optional, Union, Protocol, TypeVar
from typing_extensions import Self

# ‚úÖ GOOD: Comprehensive type annotations
class SearchEngine:
    def __init__(self, config: RepoMapConfig) -> None:
        self.config: RepoMapConfig = config
        self.cache: Dict[str, List[MatchResult]] = {}
    
    def search(
        self, 
        query: str, 
        identifiers: List[str],
        max_results: Optional[int] = None
    ) -> List[MatchResult]:
        # Implementation
        pass
    
    def get_cache_stats(self) -> Dict[str, Union[int, float]]:
        return {"size": len(self.cache), "hit_rate": 0.85}

# ‚úÖ GOOD: Generic types
T = TypeVar('T')

class Cache(Generic[T]):
    def get(self, key: str) -> Optional[T]:
        pass
    
    def set(self, key: str, value: T) -> None:
        pass

# ‚úÖ GOOD: Protocol for duck typing
class Matcher(Protocol):
    def match(self, query: str, identifiers: List[str]) -> List[MatchResult]:
        ...
```

### **MyPy Configuration Compliance:**
- **ALWAYS** use strict mode settings
- **ALWAYS** handle `Optional` types explicitly
- **ALWAYS** use `Union` types when multiple types are possible
- **ALWAYS** use `Literal` types for string/enum-like values
- **ALWAYS** use `Final` for constants

## üèóÔ∏è **PYDANTIC MODEL REQUIREMENTS**

### **Data Model Standards:**
- **ALWAYS** use Pydantic models for data validation
- **ALWAYS** define field types and constraints
- **ALWAYS** use validators for complex validation logic
- **ALWAYS** use `model_config` for Pydantic v2 settings
- **ALWAYS** use `Field()` for field metadata
- **NEVER** use plain dataclasses for validated data
- **NEVER** skip validation for user input

### **Pydantic Model Examples:**
```python
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import List, Optional, Literal
from enum import Enum

class MatchType(str, Enum):
    FUZZY = "fuzzy"
    SEMANTIC = "semantic"
    HYBRID = "hybrid"

class MatchResult(BaseModel):
    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True,
        extra="forbid"
    )
    
    identifier: str = Field(..., min_length=1, description="The matched identifier")
    score: float = Field(..., ge=0.0, le=1.0, description="Match confidence score")
    match_type: MatchType = Field(..., description="Type of matching used")
    line_number: Optional[int] = Field(None, ge=1, description="Line number in source")
    file_path: str = Field(..., description="Path to the source file")
    
    @field_validator('identifier')
    @classmethod
    def validate_identifier(cls, v: str) -> str:
        if not v.strip():
            raise ValueError("Identifier cannot be empty or whitespace only")
        return v.strip()

class SearchRequest(BaseModel):
    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True
    )
    
    query: str = Field(..., min_length=1, max_length=1000)
    match_type: MatchType = Field(default=MatchType.FUZZY)
    threshold: float = Field(default=0.7, ge=0.0, le=1.0)
    max_results: int = Field(default=50, ge=1, le=1000)
    project_path: Optional[str] = Field(None, description="Project root path")
    
    @field_validator('query')
    @classmethod
    def validate_query(cls, v: str) -> str:
        if not v.strip():
            raise ValueError("Query cannot be empty")
        return v.strip()
```

## üèõÔ∏è **ARCHITECTURE PATTERNS**

### **Class Design Principles:**
- **ALWAYS** use single responsibility principle
- **ALWAYS** prefer composition over inheritance
- **ALWAYS** use dependency injection for testability
- **ALWAYS** implement proper `__repr__` and `__str__` methods
- **ALWAYS** use context managers for resource management
- **NEVER** create god classes with multiple responsibilities
- **NEVER** use global state

### **Error Handling Standards:**
```python
from typing import NoReturn
import logging

# ‚úÖ GOOD: Custom exception hierarchy
class RepoMapError(Exception):
    """Base exception for RepoMap tool."""
    pass

class ValidationError(RepoMapError):
    """Raised when data validation fails."""
    pass

class ConfigurationError(RepoMapError):
    """Raised when configuration is invalid."""
    pass

# ‚úÖ GOOD: Proper error handling with logging
def process_file(file_path: Path) -> List[MatchResult]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return extract_identifiers(content)
    except FileNotFoundError:
        logger.error(f"File not found: {file_path}")
        raise ValidationError(f"File not found: {file_path}")
    except UnicodeDecodeError as e:
        logger.error(f"Unicode decode error in {file_path}: {e}")
        raise ValidationError(f"Invalid file encoding: {file_path}")
```

## üîß **UTILITY FUNCTIONS & HELPERS**

### **Common Patterns:**
```python
from functools import wraps
from typing import Callable, TypeVar, ParamSpec
import time

P = ParamSpec('P')
T = TypeVar('T')

# ‚úÖ GOOD: Reusable decorator
def timing_decorator(func: Callable[P, T]) -> Callable[P, T]:
    @wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        start = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start
        logger.debug(f"{func.__name__} took {duration:.3f}s")
        return result
    return wrapper

# ‚úÖ GOOD: Type-safe utility functions
def safe_divide(a: float, b: float) -> Optional[float]:
    """Safely divide two numbers, returning None if division by zero."""
    try:
        return a / b
    except ZeroDivisionError:
        return None

def normalize_path(path: Union[str, Path]) -> Path:
    """Normalize a path to a Path object."""
    if isinstance(path, str):
        return Path(path).resolve()
    return path.resolve()
```

## üì¶ **IMPORT ORGANIZATION**

### **Import Standards:**
```python
# ‚úÖ GOOD: Organized imports
from __future__ import annotations

# Standard library imports
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union

# Third-party imports
import click
from pydantic import BaseModel, Field
from rich.console import Console

# Local imports
from .models import RepoMapConfig, MatchResult
from .exceptions import RepoMapError
from .utils import timing_decorator
```

## üèóÔ∏è **DEPENDENCY INJECTION PATTERNS**

### **DI Architecture Overview:**
RepoMap-Tool uses a **hybrid DI approach** combining:
- **DI Container**: Centralized service registration and lifecycle management
- **Service Factory**: Manual service creation for CLI commands (superior to @inject for CLI)
- **Manual DI**: Explicit dependency resolution for maximum control and testability

### **DI Container Usage:**
```python
# ‚úÖ GOOD: DI Container for core services
from repomap_tool.core.container import create_container

class Container(containers.DeclarativeContainer):
    """Dependency injection container for RepoMap services."""
    
    # Configuration
    config = providers.Configuration()
    
    # Core services with proper lifecycle
    dependency_graph: "providers.Singleton[AdvancedDependencyGraph]" = cast(
        "providers.Singleton[AdvancedDependencyGraph]",
        providers.Singleton("repomap_tool.dependencies.advanced_dependency_graph.AdvancedDependencyGraph"),
    )
    
    fuzzy_matcher: "providers.Factory[FuzzyMatcher]" = cast(
        "providers.Factory[FuzzyMatcher]",
        providers.Factory(
            "repomap_tool.matchers.fuzzy_matcher.FuzzyMatcher",
            threshold=config.fuzzy_match.threshold,
            strategies=config.fuzzy_match.strategies,
            cache_results=config.fuzzy_match.cache_results,
            verbose=config.verbose,
        ),
    )
```

### **Service Factory Pattern (CLI Commands):**
```python
# ‚úÖ GOOD: Service factory for CLI commands (superior to @inject)
class ServiceFactory:
    """Factory for creating services with dependency injection."""
    
    def create_repomap_service(self, config: RepoMapConfig) -> RepoMapService:
        """Create a RepoMapService with all dependencies injected."""
        # Create DI container
        container = create_container(config)
        
        # Get all dependencies from container
        console = container.console()
        fuzzy_matcher = container.fuzzy_matcher()
        dependency_graph = container.dependency_graph()
        
        # Create service with injected dependencies
        return RepoMapService(
            config=config,
            console=console,
            fuzzy_matcher=fuzzy_matcher,
            dependency_graph=dependency_graph,
        )

# ‚úÖ GOOD: CLI command using service factory
@click.command()
def search_command(query: str, project_path: str) -> None:
    """Search command using proper DI."""
    # Get console from Click context
    console = get_console(ctx)
    
    # Create config from CLI arguments
    config = create_search_config(project_path, ...)
    
    # Get services using service factory
    service_factory = get_service_factory()
    repomap_service = service_factory.create_repomap_service(config)
    
    # Use injected services
    results = repomap_service.search(query)
```

### **Dependency Validation:**
```python
# ‚úÖ GOOD: Strict dependency validation
class RepoMapService:
    def __init__(
        self,
        config: RepoMapConfig,
        console: Optional[Any] = None,
        fuzzy_matcher: Optional[Any] = None,
        dependency_graph: Optional[Any] = None,
    ) -> None:
        # All dependencies must be injected - no fallback allowed
        if console is None:
            raise ValueError("Console must be injected - no fallback allowed")
        if fuzzy_matcher is None:
            raise ValueError("FuzzyMatcher must be injected - no fallback allowed")
        if dependency_graph is None:
            raise ValueError("DependencyGraph must be injected - no fallback allowed")
        
        self.console = console
        self.fuzzy_matcher = fuzzy_matcher
        self.dependency_graph = dependency_graph
```

### **Console DI Pattern:**
```python
# ‚úÖ GOOD: Console dependency injection
def get_console(ctx: Optional[click.Context] = None) -> Console:
    """Get console instance from Click context or global provider."""
    if ctx and ctx.obj and "console_provider" in ctx.obj:
        provider: ConsoleProvider = ctx.obj["console_provider"]
        return provider.get_console(ctx)
    
    # Fallback to global provider
    provider = get_console_provider()
    return provider.get_console(ctx)

# ‚ùå BAD: Direct console instantiation
console = Console()  # Bypasses DI system
```

### **DI Anti-Patterns to Avoid:**
```python
# ‚ùå BAD: Direct service instantiation
matcher = FuzzyMatcher(threshold=70)  # Bypasses DI container

# ‚ùå BAD: Fallback instantiation
self.console = console or Console()  # Should raise error instead

# ‚ùå BAD: Global service access
from repomap_tool.core.container import get_container
container = get_container()  # Use service factory instead

# ‚ùå BAD: @inject decorators for CLI commands
@inject
def search_command(
    console: Console = Provide[Container.console]  # Wrong for CLI
) -> None:
    pass
```

### **DI Testing Patterns:**
```python
# ‚úÖ GOOD: Test using service factory
def test_search_functionality():
    """Test using proper DI patterns."""
    # Create test config
    config = create_test_config()
    
    # Use service factory (same as production)
    service_factory = get_service_factory()
    repomap_service = service_factory.create_repomap_service(config)
    
    # Test with real injected dependencies
    results = repomap_service.search("test query")
    assert len(results) > 0

# ‚ùå BAD: Direct instantiation in tests
def test_search_functionality():
    matcher = FuzzyMatcher(threshold=70)  # Bypasses DI
    results = matcher.match("test", ["test_data"])
```

### **DI Best Practices:**
- **ALWAYS** use service factory for CLI commands (not @inject decorators)
- **ALWAYS** validate dependencies are injected (no fallback instantiation)
- **ALWAYS** use DI container for core service registration
- **ALWAYS** get console from Click context, never instantiate directly
- **ALWAYS** use same DI patterns in tests as production code
- **NEVER** bypass DI system with direct instantiation
- **NEVER** use @inject decorators for CLI commands (manual DI is superior)
- **NEVER** create services outside the DI container

## üß™ **TESTING INTEGRATION**

### **Testable Code Patterns:**
```python
# ‚úÖ GOOD: Dependency injection for testability
class SearchEngine:
    def __init__(
        self, 
        config: RepoMapConfig,
        matcher: Optional[Matcher] = None,
        cache: Optional[Cache[MatchResult]] = None
    ) -> None:
        self.config = config
        self.matcher = matcher or DefaultMatcher(config)
        self.cache = cache or MemoryCache()
    
    def search(self, request: SearchRequest) -> List[MatchResult]:
        # Implementation that can be easily mocked in tests
        pass
```

## üö® **MANDATORY COMPLETION CHECKLIST**

### **Before claiming work is complete:**
- [ ] **Code is formatted**: `make format` has been run
- [ ] **Linting passes**: `make lint` shows no errors
- [ ] **Type checking passes**: `make mypy` shows no errors
- [ ] **All functions have type annotations**
- [ ] **All data models use Pydantic**
- [ ] **No code duplication exists**
- [ ] **Error handling is comprehensive**
- [ ] **Logging is appropriate**
- [ ] **Documentation strings are present**
- [ ] **Tests pass**: `make test` succeeds
- [ ] **DI compliance**: All services use dependency injection
- [ ] **No direct instantiation**: No `Console()`, `FuzzyMatcher()`, etc. outside DI
- [ ] **Service factory usage**: CLI commands use service factory pattern
- [ ] **Dependency validation**: All dependencies validated in constructors

## üîç **MANDATORY VERIFICATION PROTOCOL**

### **CRITICAL: Before claiming ANY task is complete, you MUST:**

#### **1. Deep Search Verification**
- [ ] **Perform comprehensive codebase search** to verify the task was actually completed
- [ ] **Search for all related patterns** to ensure nothing was missed
- [ ] **Verify no old implementations remain** that contradict the new changes
- [ ] **Confirm all references were updated** to use the new implementation
- [ ] **Check for any remaining dead code** or unused imports

#### **2. Dead Code Removal**
- [ ] **Identify and remove all dead code** left behind after refactoring
- [ ] **Remove unused imports** and dependencies
- [ ] **Delete obsolete files** that are no longer needed
- [ ] **Clean up DI container** references to removed services
- [ ] **Verify no broken references** remain in the codebase

#### **3. Build Verification**
- [ ] **Run `make format`** to ensure code formatting is correct
- [ ] **Run `make lint`** to check for style issues
- [ ] **Run `make mypy`** to verify type safety
- [ ] **Run `make test-unit`** to ensure all tests pass
- [ ] **Build Docker image** to verify the application works in production environment
- [ ] **Test the actual functionality** to ensure it works as expected

### **üîç Deep Search Requirements:**

#### **For Refactoring Tasks:**
```bash
# Search for old patterns that should be replaced
grep -r "old_pattern" src/repomap_tool/
# Search for new patterns to verify implementation
grep -r "new_pattern" src/repomap_tool/
# Search for any remaining references to old code
grep -r "old_class_name" src/repomap_tool/
```

#### **For Dead Code Detection:**
```bash
# Search for unused imports
grep -r "import.*unused_module" src/repomap_tool/
# Search for unused DI providers
grep -r "unused_provider" src/repomap_tool/core/container.py
# Search for files that are imported but never used
find src/repomap_tool/ -name "*.py" -exec grep -l "import.*filename" {} \;
```

#### **For Build Verification:**
```bash
# Format and lint
make format && make lint && make mypy
# Run tests
make test-unit
# Build Docker image
docker build -f docker/Dockerfile -t repomap-tool:local .
# Test functionality
docker run --rm -t -v /path/to/test:/workspace repomap-tool:local <command>
```

### **üö® ANTI-CHEATING PROTOCOLS**

#### **What Constitutes Incomplete Work:**
- [ ] **Claiming completion without deep search verification**
- [ ] **Leaving dead code behind after refactoring**
- [ ] **Not building and testing the final result**
- [ ] **Missing references to old implementations**
- [ ] **Broken imports or dependencies**
- [ ] **Failing tests or build errors**

#### **Quality Gates:**
- [ ] **Zero dead code** - All obsolete code must be removed
- [ ] **Zero broken references** - All imports and dependencies must work
- [ ] **Zero build errors** - Application must build and run successfully
- [ ] **Zero test failures** - All tests must pass
- [ ] **Complete verification** - Deep search must confirm task completion

### **üìã Verification Checklist Template:**

```markdown
## ‚úÖ TASK COMPLETION VERIFICATION

### **Deep Search Results:**
- [ ] Searched for old patterns: `grep -r "old_pattern" src/` ‚Üí No results found
- [ ] Searched for new patterns: `grep -r "new_pattern" src/` ‚Üí X results found
- [ ] Verified no old references: `grep -r "old_class" src/` ‚Üí No results found
- [ ] Confirmed new implementation: `grep -r "new_class" src/` ‚Üí X results found

### **Dead Code Removal:**
- [ ] Removed unused files: `deleted_file.py` (X lines)
- [ ] Removed unused imports: X imports cleaned up
- [ ] Removed unused DI providers: X providers removed
- [ ] Cleaned up references: X references updated

### **Build Verification:**
- [ ] `make format` ‚Üí ‚úÖ Passed
- [ ] `make lint` ‚Üí ‚úÖ Passed  
- [ ] `make mypy` ‚Üí ‚úÖ Passed
- [ ] `make test-unit` ‚Üí ‚úÖ Passed
- [ ] `docker build` ‚Üí ‚úÖ Passed
- [ ] `docker run <command>` ‚Üí ‚úÖ Passed

### **Final Status:**
- [ ] **Task 100% complete** with full verification
- [ ] **No dead code remaining**
- [ ] **All builds and tests passing**
- [ ] **Functionality verified working**
```

### **Code Quality Gates:**
- **Line length**: ‚â§88 characters (Black standard)
- **Function length**: ‚â§50 lines
- **Class length**: ‚â§300 lines
- **Cyclomatic complexity**: ‚â§10 per function
- **Type coverage**: 100% for new code
- **Pydantic usage**: 100% for data models

## üéØ **SUCCESS CRITERIA**

**Code is considered complete when:**
- All formatting tools pass without errors
- MyPy reports no type errors
- No code duplication exists
- All data validation uses Pydantic
- Error handling is comprehensive
- Code follows DRY principles
- Type annotations are complete and accurate
- Modern Python patterns are used throughout
- **Dependency injection is properly implemented**
- **No direct service instantiation outside DI container**
- **CLI commands use service factory pattern**
- **All dependencies are validated and injected**