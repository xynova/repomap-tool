---
description: Architecture rules for AI (Cursor) to follow when developing RepoMap-Tool
globs:
alwaysApply: true
---

# 🤖 **AI DEVELOPMENT RULES FOR REPOMAP-TOOL**

> **For AI (Cursor)**: These are the architectural rules you must follow when developing, modifying, or extending the RepoMap-Tool codebase.

## 🎯 **CORE ARCHITECTURAL PRINCIPLES**

### **Centralized Output Management**
- **ALL CLI output** must go through the `OutputManager` system
- **NO direct `console.print()` calls** in CLI commands (except utility functions)
- **Consistent formatting** across all commands and output types
- **Template-based rendering** for maintainable and flexible output

### **Dependency Injection (DI) Compliance**
- **ALL services** must use proper DI patterns
- **Constructor injection** is the preferred DI pattern for all services
- **NO direct instantiation** of services outside DI container
- **Service Factory pattern** for CLI commands (superior to @inject decorators)
- **Strict dependency validation** - no fallback instantiation allowed

### **Type Safety & Validation**
- **Full MyPy compliance** with comprehensive type annotations
- **Pydantic models** for all data structures and validation
- **Protocol-based interfaces** for extensibility and testability

### **AI Development Guidelines**
- **ALWAYS follow existing patterns** - don't reinvent the wheel
- **ALWAYS use dependency injection** - never instantiate services directly
- **ALWAYS validate dependencies** - raise errors for missing dependencies
- **ALWAYS use the OutputManager** - never use direct console.print in CLI commands
- **ALWAYS follow the template system** - use Jinja2 templates for output formatting
- **ALWAYS implement proper error handling** - use custom exception hierarchy
- **ALWAYS write comprehensive tests** - maintain >80% test coverage
- **ALWAYS use the existing DI container** - don't create new service factories
- **ALWAYS follow the caching patterns** - use TTL-based caching with statistics
- **ALWAYS use the existing matcher protocols** - implement MatcherProtocol interface

### **Matching Algorithm Architecture**
- **Strategy Pattern** for multiple matching approaches (fuzzy, semantic, hybrid)
- **Cache-First Design** with configurable TTL for performance
- **Threshold-Based Filtering** with configurable sensitivity
- **Adaptive Learning** from actual codebase content (TF-IDF, semantic analysis)

### **LLM Optimization Architecture**
- **Token Budget Management** for context window optimization
- **Context Selection Strategies** (breadth-first, depth-first, hybrid, centrality-based)
- **Critical Line Extraction** using tree-sitter for code analysis
- **Signature Enhancement** with type inference and usage patterns
- **Hierarchical Formatting** for LLM-friendly structure

### **Tree Exploration Architecture**
- **Session-Based State Management** for persistent tree operations
- **Tree Builder Pattern** for constructing exploration trees
- **Tree Manager Pattern** for tree operations (expand, prune, focus)
- **Entrypoint Discovery** for finding code entry points
- **Dependency-Aware Construction** using dependency analysis

### **Dependency Analysis Architecture**
- **Graph-Based Representation** using NetworkX for dependency graphs
- **Import Analysis** using AST-based parsing
- **Centrality Analysis** for identifying critical nodes
- **Impact Analysis** for risk assessment of changes
- **Multi-Language Support** (Python, JavaScript/TypeScript)

### **Caching & Performance Architecture**
- **Multi-Level Caching** (service-level, matcher-level, tree-level)
- **TTL-Based Expiration** with configurable lifetimes
- **Parallel Processing** for multi-threaded operations
- **Memory Management** with configurable limits
- **Cache Statistics** for monitoring and optimization

## 🏛️ **OUTPUT ARCHITECTURE OVERVIEW**

### **Core Components**

#### **1. OutputManager** (`src/repomap_tool/cli/output/manager.py`)
```python
# Central hub for all CLI output operations
class OutputManager:
    def display(self, data: Any, output_format: OutputFormat, ctx: Optional[click.Context] = None) -> None
    def display_error(self, error: Exception, ctx: Optional[click.Context] = None) -> None
    def display_success(self, message: str, ctx: Optional[click.Context] = None) -> None
    def display_progress(self, message: str, progress: Optional[float] = None, ctx: Optional[click.Context] = None) -> None
```

#### **2. ConsoleManager** (`src/repomap_tool/cli/output/console_manager.py`)
```python
# Centralized console management and configuration
class ConsoleManager:
    def get_console(self, ctx: Optional[click.Context] = None) -> Console
    def configure_console(self, config: ConsoleConfig) -> None
    def log_operation(self, operation: str, details: Dict[str, Any]) -> None
```

#### **3. FormatterRegistry** (`src/repomap_tool/cli/output/standard_formatters.py`)
```python
# Registry for all output formatters
class FormatterRegistry:
    def register_formatter(self, data_type: Type, formatter: FormatterProtocol) -> None
    def get_formatter(self, data_type: Type, output_format: OutputFormat) -> Optional[FormatterProtocol]
```

#### **4. Template System** (`src/repomap_tool/cli/output/templates/`)
```python
# Jinja2-based templating for flexible output generation
class TemplateEngine:
    def render_template(self, template_name: str, context: Dict[str, Any]) -> str
    def register_template(self, name: str, template: str) -> None
```

### **Output Format Hierarchy**

#### **CLI Output Formats** (for general CLI commands)
```python
class OutputFormat(str, Enum):
    JSON = "json"           # Machine-readable JSON output
    TEXT = "text"           # Rich, hierarchical, token-optimized format (default)
```

#### **Analysis Formats** (for LLM analysis)
```python
class AnalysisFormat(str, Enum):
    TEXT = "text"           # Rich, hierarchical, token-optimized format (default)
    JSON = "json"           # Raw data for programmatic consumption
```

## 🔧 **IMPLEMENTATION PATTERNS**

### **Matching Algorithm Pattern**
```python
# Strategy Pattern for multiple matching approaches
class MatcherProtocol(Protocol):
    def match_identifiers(self, query: str, all_identifiers: Set[str]) -> List[Tuple[str, int]]: ...
    def clear_cache(self) -> None: ...
    def get_cache_stats(self) -> Dict[str, Any]: ...

class FuzzyMatcher:
    def __init__(self, threshold: int = 70, strategies: List[str] = None):
        self.threshold = threshold
        self.strategies = strategies or ["prefix", "suffix", "substring", "levenshtein"]
        self.cache = CacheManager(max_size=1000, ttl=3600)
    
    def match_identifiers(self, query: str, all_identifiers: Set[str]) -> List[Tuple[str, int]]:
        # Check cache first
        cache_key = f"fuzzy_{query}_{hash(frozenset(all_identifiers))}"
        if cached_result := self.cache.get(cache_key):
            return cached_result
        
        # Apply multiple strategies
        matches = []
        for strategy in self.strategies:
            strategy_matches = self._apply_strategy(strategy, query, all_identifiers)
            matches.extend(strategy_matches)
        
        # Cache and return results
        self.cache.set(cache_key, matches)
        return matches
```

### **LLM Optimization Pattern**
```python
# Token budget management and context selection
class TokenOptimizer:
    def __init__(self, max_tokens: int = 8000):
        self.max_tokens = max_tokens
        self.token_estimator = TokenEstimator()
    
    def optimize_context(self, data: Any, strategy: SelectionStrategy) -> ContextSelection:
        # Estimate token usage
        estimated_tokens = self.token_estimator.estimate_tokens(data)
        
        if estimated_tokens <= self.max_tokens:
            return ContextSelection(data=data, tokens_used=estimated_tokens)
        
        # Apply selection strategy
        if strategy == SelectionStrategy.CENTRALITY_BASED:
            return self._select_by_centrality(data)
        elif strategy == SelectionStrategy.BREADTH_FIRST:
            return self._select_breadth_first(data)
        # ... other strategies
    
    def _select_by_centrality(self, data: Any) -> ContextSelection:
        # Prioritize by dependency centrality
        centrality_scores = self._calculate_centrality(data)
        selected = self._select_top_by_centrality(data, centrality_scores)
        return ContextSelection(data=selected, tokens_used=self.token_estimator.estimate_tokens(selected))
```

### **Tree Exploration Pattern**
```python
# Session-based tree management
class TreeManager:
    def __init__(self, session_manager: SessionManager, tree_builder: TreeBuilder):
        if session_manager is None:
            raise ValueError("SessionManager must be injected - no fallback allowed")
        if tree_builder is None:
            raise ValueError("TreeBuilder must be injected - no fallback allowed")
        
        self.session_manager = session_manager
        self.tree_builder = tree_builder
    
    def expand_tree(self, session_id: str, tree_id: str, node_id: str) -> bool:
        # Get session and tree
        session = self.session_manager.get_session(session_id)
        tree = session.get_tree(tree_id)
        
        # Find and expand node
        node = self._find_node(tree, node_id)
        if node and not node.expanded:
            self._expand_node(node, tree)
            self.session_manager.save_session(session)
            return True
        return False
    
    def _expand_node(self, node: TreeNode, tree: ExplorationTree) -> None:
        # Use dependency analysis to find related nodes
        dependencies = self._get_node_dependencies(node)
        for dep in dependencies:
            child = TreeNode(
                identifier=dep.name,
                location=dep.location,
                node_type=dep.type,
                depth=node.depth + 1
            )
            child.parent = node
            node.children.append(child)
        node.expanded = True
```

### **Dependency Analysis Pattern**
```python
# Graph-based dependency analysis
class DependencyGraph:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.import_analyzer = ImportAnalyzer()
    
    def build_graph(self, project_imports: ProjectImports) -> None:
        # Add nodes for each file
        for file_path, imports in project_imports.files.items():
            self.graph.add_node(file_path, imports=imports)
        
        # Add edges for dependencies
        for file_path, imports in project_imports.files.items():
            for import_stmt in imports.imports:
                if import_stmt.resolved_path:
                    self.graph.add_edge(file_path, import_stmt.resolved_path)
    
    def calculate_centrality(self) -> Dict[str, float]:
        # Calculate betweenness centrality
        centrality = nx.betweenness_centrality(self.graph)
        return centrality
    
    def find_impact_scope(self, changed_file: str) -> List[str]:
        # Find all files that depend on the changed file
        dependents = list(nx.descendants(self.graph, changed_file))
        return dependents
```

### **Caching Pattern**
```python
# Multi-level caching with TTL
class CacheManager:
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache: Dict[str, CacheEntry] = {}
        self.access_times: Dict[str, float] = {}
    
    def get(self, key: str) -> Optional[Any]:
        if key not in self.cache:
            return None
        
        entry = self.cache[key]
        if self._is_expired(entry):
            self._remove(key)
            return None
        
        # Update access time for LRU
        self.access_times[key] = time.time()
        return entry.value
    
    def set(self, key: str, value: Any) -> None:
        # Check size limit
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        # Store with TTL
        self.cache[key] = CacheEntry(value=value, created_at=time.time())
        self.access_times[key] = time.time()
    
    def _is_expired(self, entry: CacheEntry) -> bool:
        return time.time() - entry.created_at > self.ttl
```

### **Constructor DI Pattern**
```python
# PREFERRED - Constructor injection with strict validation
class ExampleService:
    def __init__(
        self,
        config: RepoMapConfig,
        console: Console,
        matcher: FuzzyMatcher,
        formatter: ProjectInfoFormatter,
    ) -> None:
        # All dependencies must be injected - no fallback allowed
        if console is None:
            raise ValueError("Console must be injected - no fallback allowed")
        if matcher is None:
            raise ValueError("FuzzyMatcher must be injected - no fallback allowed")
        if formatter is None:
            raise ValueError("ProjectInfoFormatter must be injected - no fallback allowed")
        
        self.config = config
        self.console = console
        self.matcher = matcher
        self.formatter = formatter
    
    def process(self) -> str:
        # Use injected dependencies
        result = self.matcher.match("query", ["data"])
        return self.formatter.format(result, OutputFormat.TEXT)
```

### **CLI Command Pattern**
```python
@click.command()
def example_command(ctx: click.Context, format: str) -> None:
    """Example command using proper output architecture."""
    # Get services via DI
    service_factory = get_service_factory()
    repomap_service = service_factory.create_repomap_service(config)
    output_manager = get_output_manager()
    
    try:
        # Perform business logic
        result = repomap_service.analyze_project()
        
        # Display via OutputManager
        output_format = OutputFormat(format)
        output_manager.display(result, output_format, ctx)
        
    except Exception as e:
        # Error handling via OutputManager
        output_manager.display_error(e, ctx)
```

### **Formatter Implementation Pattern**
```python
class ExampleFormatter(BaseFormatter):
    """Formatter for ExampleData objects."""
    
    def supports_format(self, output_format: OutputFormat) -> bool:
        return output_format in [OutputFormat.TEXT, OutputFormat.JSON]
    
    def format(self, data: ExampleData, output_format: OutputFormat, ctx: Optional[click.Context] = None) -> str:
        if output_format == OutputFormat.JSON:
            return self._format_json(data)
        elif output_format == OutputFormat.TEXT:
            return self._format_text(data)
        else:
            raise ValueError(f"Unsupported format: {output_format}")
    
    def _format_text(self, data: ExampleData) -> str:
        # Use template system for consistent formatting
        return self._template_engine.render_template("example.jinja2", {"data": data})
```

### **Jinja2 Template Pattern**
```jinja2
{# Standard Template Structure #}
{# Template Name: example.jinja2 #}
{% set emoji = config.options.use_emojis if config and config.options else true %}
{% set hierarchical = config.options.use_hierarchical_structure if config and config.options else true %}

{# Header with conditional emoji #}
{% if emoji %}🔍 Example Analysis{% else %}Example Analysis{% endif %}
{{ "=" * 60 }}

{# Summary section #}
{% if emoji %}📊{% endif %} SUMMARY:
{% if hierarchical %}├──{% else %}•{% endif %} Total Items: {{ data.total_items }}
{% if hierarchical %}└──{% else %}•{% endif %} Processing Time: {{ data.processing_time_ms | format_duration }}

{# Results section with conditional display #}
{% if data.results %}
{% if emoji %}🎯{% endif %} RESULTS:
{% for result in data.results %}
{% if hierarchical %}├──{% else %}•{% endif %} {{ result.name }}
{% if hierarchical %}│   {% else %}  {% endif %}Score: {{ result.score | format_percentage }}
{% if not loop.last %}
{% if hierarchical %}│{% endif %}
{% endif %}
{% endfor %}
{% else %}
{% if emoji %}❌{% endif %} No results found
{% endif %}
```

#### **Template Pattern Rules:**
1. **Configuration-Driven**: Use `config.options` for conditional rendering
2. **Emoji Support**: Always provide emoji and non-emoji variants
3. **Hierarchical Structure**: Support both hierarchical (├──) and flat (•) layouts
4. **Consistent Formatting**: Use standard separators and indentation
5. **Conditional Sections**: Only show sections when data is available
6. **Custom Filters**: Use filters like `format_percentage`, `format_duration`
7. **Loop Handling**: Proper handling of loop boundaries and separators

## 🚫 **ANTI-PATTERNS TO AVOID (AI MUST NOT DO THESE)**

### **❌ Direct Console Usage**
```python
# WRONG - AI must never do this
@click.command()
def bad_command():
    console = Console()  # ❌ AI: Don't instantiate Console directly
    console.print("Bad output")  # ❌ AI: Don't use console.print in CLI commands
```

### **❌ Direct Service Instantiation**
```python
# WRONG - AI must never do this
def bad_function():
    matcher = FuzzyMatcher(threshold=0.7)  # ❌ AI: Don't bypass DI
    formatter = ProjectInfoFormatter()     # ❌ AI: Don't bypass DI
```

### **❌ AI Anti-Patterns**
```python
# WRONG - AI must never do these things
class BadAICode:
    def __init__(self):
        # ❌ AI: Don't create services directly
        self.matcher = FuzzyMatcher()
        self.cache = CacheManager()
        
        # ❌ AI: Don't use fallback instantiation
        self.console = Console() if console is None else console
        
        # ❌ AI: Don't bypass the OutputManager
        console.print("Direct output")  # Use OutputManager instead
        
        # ❌ AI: Don't create new service factories
        self.service = SomeService()  # Use existing DI container
        
        # ❌ AI: Don't skip dependency validation
        self.dependency = dependency  # Should validate and raise error if None
```

### **❌ Constructor DI Violations**
```python
# WRONG - Fallback instantiation in constructor
class BadService:
    def __init__(self, console: Optional[Console] = None):
        self.console = console or Console()  # Should raise error instead

# WRONG - Missing dependency validation
class BadService:
    def __init__(self, console: Optional[Console] = None):
        self.console = console  # No validation - could be None
```

### **❌ Fallback Instantiation**
```python
# WRONG - Fallback instantiation
class BadService:
    def __init__(self, console: Optional[Console] = None):
        self.console = console or Console()  # Should raise error instead
```

### **❌ Mixed Output Patterns**
```python
# WRONG - Mixing OutputManager and direct console
def bad_function():
    output_manager.display("Good output")
    console.print("Bad output")  # Inconsistent
```

### **❌ Template Anti-Patterns**
```jinja2
{# WRONG - Hardcoded values without configuration #}
🔍 Search Results
{{ "=" * 60 }}
• Query: {{ data.query }}
• Results: {{ data.results|length }}

{# WRONG - No emoji alternatives #}
🔍 Search Results  {# Always shows emoji #}

{# WRONG - Inconsistent formatting #}
• Item 1
  - Subitem 1
• Item 2
  - Subitem 2  {# Inconsistent indentation #}

{# WRONG - No conditional sections #}
📊 Results: {{ data.results|length }}  {# Shows even when empty #}
```

### **❌ Matching Algorithm Anti-Patterns**
```python
# WRONG - No caching
class BadMatcher:
    def match_identifiers(self, query: str, identifiers: Set[str]) -> List[Tuple[str, int]]:
        # Always recalculates - no caching
        return self._calculate_matches(query, identifiers)

# WRONG - Single strategy only
class BadMatcher:
    def match_identifiers(self, query: str, identifiers: Set[str]) -> List[Tuple[str, int]]:
        # Only uses exact matching - inflexible
        return [(id, 100) for id in identifiers if query == id]

# WRONG - No threshold configuration
class BadMatcher:
    def match_identifiers(self, query: str, identifiers: Set[str]) -> List[Tuple[str, int]]:
        # Hardcoded threshold - not configurable
        return [(id, score) for id, score in self._calculate_scores(query, identifiers) if score >= 80]
```

### **❌ LLM Optimization Anti-Patterns**
```python
# WRONG - No token budget management
class BadLLMOptimizer:
    def optimize_output(self, data: Any) -> str:
        # Always returns full data - no token limits
        return str(data)

# WRONG - No context selection
class BadLLMOptimizer:
    def optimize_output(self, data: Any) -> str:
        # No strategy for selecting relevant context
        return self._format_all_data(data)

# WRONG - No hierarchical structure
class BadLLMOptimizer:
    def optimize_output(self, data: Any) -> str:
        # Flat output - not LLM-friendly
        return "\n".join([str(item) for item in data])
```

### **❌ Tree Exploration Anti-Patterns**
```python
# WRONG - No session management
class BadTreeManager:
    def expand_tree(self, tree_id: str, node_id: str) -> bool:
        # No session tracking - state lost between operations
        tree = self._get_tree(tree_id)
        return self._expand_node(tree, node_id)

# WRONG - No dependency awareness
class BadTreeManager:
    def expand_node(self, node: TreeNode) -> None:
        # Random expansion - not based on actual dependencies
        random_children = self._get_random_children(node)
        node.children.extend(random_children)

# WRONG - No caching
class BadTreeManager:
    def build_tree(self, entrypoint: Entrypoint) -> ExplorationTree:
        # Always rebuilds - no caching
        return self._build_from_scratch(entrypoint)
```

### **❌ Dependency Analysis Anti-Patterns**
```python
# WRONG - No graph representation
class BadDependencyAnalyzer:
    def analyze_dependencies(self, files: List[str]) -> Dict[str, List[str]]:
        # Simple dict - no graph algorithms available
        dependencies = {}
        for file in files:
            dependencies[file] = self._find_imports(file)
        return dependencies

# WRONG - No centrality analysis
class BadDependencyAnalyzer:
    def find_critical_files(self, files: List[str]) -> List[str]:
        # Random selection - not based on actual centrality
        return random.sample(files, min(5, len(files)))

# WRONG - No impact analysis
class BadDependencyAnalyzer:
    def analyze_change_impact(self, changed_file: str) -> List[str]:
        # No impact analysis - just returns the file itself
        return [changed_file]
```

### **❌ Caching Anti-Patterns**
```python
# WRONG - No TTL management
class BadCache:
    def __init__(self):
        self.cache = {}
    
    def get(self, key: str) -> Optional[Any]:
        # No expiration - cache grows indefinitely
        return self.cache.get(key)

# WRONG - No size limits
class BadCache:
    def set(self, key: str, value: Any) -> None:
        # No size management - memory leak potential
        self.cache[key] = value

# WRONG - No cache statistics
class BadCache:
    def get_stats(self) -> Dict[str, Any]:
        # No monitoring - can't optimize
        return {"size": len(self.cache)}
```

## ✅ **CORRECT PATTERNS (AI MUST DO THESE)**

### **✅ AI-Required Constructor DI Usage**
```python
# CORRECT - AI must always do this
class GoodService:
    def __init__(
        self,
        config: RepoMapConfig,
        console: Console,
        matcher: FuzzyMatcher,
    ) -> None:
        # ✅ AI: Always validate dependencies strictly
        if console is None:
            raise ValueError("Console must be injected - no fallback allowed")
        if matcher is None:
            raise ValueError("FuzzyMatcher must be injected - no fallback allowed")
        
        self.config = config
        self.console = console
        self.matcher = matcher

# CORRECT - AI must use service factory pattern
def good_function():
    # ✅ AI: Always use existing service factory
    service_factory = get_service_factory()
    service = service_factory.create_service(config)  # Uses constructor DI
    
    # ✅ AI: Always use OutputManager for output
    output_manager = get_output_manager()
    
    result = service.process()
    output_manager.display(result, OutputFormat.TEXT)
```

### **✅ AI-Required Patterns**
```python
# CORRECT - AI must always follow these patterns
class GoodAICode:
    def __init__(self, dependency: SomeService):
        # ✅ AI: Always validate dependencies
        if dependency is None:
            raise ValueError("Dependency must be injected - no fallback allowed")
        self.dependency = dependency
    
    def process_data(self, data: Any) -> str:
        # ✅ AI: Always use OutputManager for output
        output_manager = get_output_manager()
        
        try:
            result = self.dependency.process(data)
            # ✅ AI: Always use proper output formatting
            output_manager.display_success("Processing completed")
            return result
        except Exception as e:
            # ✅ AI: Always use proper error handling
            output_manager.display_error(e)
            raise
    
    def create_new_service(self, config: RepoMapConfig) -> SomeService:
        # ✅ AI: Always use existing DI container
        container = get_container()
        return container.some_service(config)
```

### **✅ Strict Dependency Validation**
```python
# CORRECT - Strict validation
class GoodService:
    def __init__(self, console: Optional[Console] = None):
        if console is None:
            raise ValueError("Console must be injected - no fallback allowed")
        self.console = console
```

### **✅ Template-Based Formatting**
```python
# CORRECT - Template-based output
class GoodFormatter(BaseFormatter):
    def format(self, data: Any, output_format: OutputFormat) -> str:
        template_name = f"{type(data).__name__.lower()}.jinja2"
        return self._template_engine.render_template(template_name, {"data": data})
```

### **✅ Template Best Practices**
```jinja2
{# CORRECT - Configuration-driven template #}
{# Template: search_response.jinja2 #}
{% set emoji = config.options.use_emojis if config and config.options else true %}
{% set hierarchical = config.options.use_hierarchical_structure if config and config.options else true %}

{# Header with conditional emoji #}
{% if emoji %}🔍 Search Results{% else %}Search Results{% endif %}
{{ "=" * 60 }}

{# Summary with consistent formatting #}
{% if emoji %}📊{% endif %} QUERY: "{{ data.query }}"
{% if hierarchical %}├──{% else %}•{% endif %} Match Type: {{ data.match_type }}
{% if hierarchical %}├──{% else %}•{% endif %} Threshold: {{ data.threshold | format_percentage }}
{% if hierarchical %}└──{% else %}•{% endif %} Total Results: {{ data.total_results }}

{# Conditional results section #}
{% if data.results %}
{% if emoji %}🎯{% endif %} RESULTS:
{% for result in data.results %}
{% if hierarchical %}├──{% else %}•{% endif %} {{ result.identifier }}
{% if hierarchical %}│   {% else %}  {% endif %}Score: {{ result.score | format_percentage }}
{% if not loop.last %}
{% if hierarchical %}│{% endif %}
{% endif %}
{% endfor %}
{% else %}
{% if emoji %}❌{% endif %} No results found
{% endif %}
```

### **✅ Matching Algorithm Best Practices**
```python
# CORRECT - Multi-strategy with caching
class GoodMatcher:
    def __init__(self, threshold: int = 70, strategies: List[str] = None, cache_manager: CacheManager = None):
        if cache_manager is None:
            raise ValueError("CacheManager must be injected - no fallback allowed")
        
        self.threshold = threshold
        self.strategies = strategies or ["prefix", "suffix", "substring", "levenshtein"]
        self.cache = cache_manager
    
    def match_identifiers(self, query: str, all_identifiers: Set[str]) -> List[Tuple[str, int]]:
        # Check cache first
        cache_key = f"match_{hash(query)}_{hash(frozenset(all_identifiers))}"
        if cached_result := self.cache.get(cache_key):
            return cached_result
        
        # Apply multiple strategies
        matches = []
        for strategy in self.strategies:
            strategy_matches = self._apply_strategy(strategy, query, all_identifiers)
            matches.extend(strategy_matches)
        
        # Filter by threshold and sort
        filtered_matches = [(id, score) for id, score in matches if score >= self.threshold]
        filtered_matches.sort(key=lambda x: x[1], reverse=True)
        
        # Cache and return
        self.cache.set(cache_key, filtered_matches)
        return filtered_matches
```

### **✅ LLM Optimization Best Practices**
```python
# CORRECT - Token budget management with context selection
class GoodLLMOptimizer:
    def __init__(self, token_optimizer: TokenOptimizer, context_selector: ContextSelector):
        if token_optimizer is None:
            raise ValueError("TokenOptimizer must be injected - no fallback allowed")
        if context_selector is None:
            raise ValueError("ContextSelector must be injected - no fallback allowed")
        
        self.token_optimizer = token_optimizer
        self.context_selector = context_selector
    
    def optimize_for_llm(self, data: Any, max_tokens: int = 8000, strategy: SelectionStrategy = SelectionStrategy.CENTRALITY_BASED) -> str:
        # Estimate token usage
        estimated_tokens = self.token_optimizer.estimate_tokens(data)
        
        if estimated_tokens <= max_tokens:
            return self._format_hierarchical(data)
        
        # Select optimal context
        context_selection = self.context_selector.select_context(data, max_tokens, strategy)
        
        # Format with hierarchical structure
        return self._format_hierarchical(context_selection.data)
    
    def _format_hierarchical(self, data: Any) -> str:
        # Use hierarchical formatter for LLM-friendly output
        formatter = HierarchicalFormatter()
        return formatter.format(data)
```

### **✅ Tree Exploration Best Practices**
```python
# CORRECT - Session-based with dependency awareness
class GoodTreeManager:
    def __init__(self, session_manager: SessionManager, tree_builder: TreeBuilder, dependency_graph: DependencyGraph):
        if session_manager is None:
            raise ValueError("SessionManager must be injected - no fallback allowed")
        if tree_builder is None:
            raise ValueError("TreeBuilder must be injected - no fallback allowed")
        if dependency_graph is None:
            raise ValueError("DependencyGraph must be injected - no fallback allowed")
        
        self.session_manager = session_manager
        self.tree_builder = tree_builder
        self.dependency_graph = dependency_graph
    
    def expand_tree(self, session_id: str, tree_id: str, node_id: str) -> bool:
        # Get session and tree
        session = self.session_manager.get_session(session_id)
        tree = session.get_tree(tree_id)
        
        # Find and expand node
        node = self._find_node(tree, node_id)
        if node and not node.expanded:
            # Use dependency analysis for intelligent expansion
            self._expand_node_with_dependencies(node, tree)
            self.session_manager.save_session(session)
            return True
        return False
    
    def _expand_node_with_dependencies(self, node: TreeNode, tree: ExplorationTree) -> None:
        # Get actual dependencies from dependency graph
        file_path = self._extract_file_path(node.location)
        if file_path:
            dependencies = self.dependency_graph.get_dependencies(file_path)
            for dep in dependencies:
                child = TreeNode(
                    identifier=dep.name,
                    location=dep.location,
                    node_type=dep.type,
                    depth=node.depth + 1
                )
                child.parent = node
                node.children.append(child)
        node.expanded = True
```

### **✅ Dependency Analysis Best Practices**
```python
# CORRECT - Graph-based with centrality analysis
class GoodDependencyAnalyzer:
    def __init__(self, import_analyzer: ImportAnalyzer, centrality_calculator: CentralityCalculator):
        if import_analyzer is None:
            raise ValueError("ImportAnalyzer must be injected - no fallback allowed")
        if centrality_calculator is None:
            raise ValueError("CentralityCalculator must be injected - no fallback allowed")
        
        self.graph = nx.DiGraph()
        self.import_analyzer = import_analyzer
        self.centrality_calculator = centrality_calculator
    
    def build_dependency_graph(self, project_imports: ProjectImports) -> None:
        # Add nodes for each file
        for file_path, imports in project_imports.files.items():
            self.graph.add_node(file_path, imports=imports)
        
        # Add edges for dependencies
        for file_path, imports in project_imports.files.items():
            for import_stmt in imports.imports:
                if import_stmt.resolved_path:
                    self.graph.add_edge(file_path, import_stmt.resolved_path)
    
    def find_critical_files(self, top_n: int = 10) -> List[Tuple[str, float]]:
        # Calculate centrality scores
        centrality_scores = self.centrality_calculator.calculate_centrality(self.graph)
        
        # Sort by centrality and return top N
        sorted_files = sorted(centrality_scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_files[:top_n]
    
    def analyze_change_impact(self, changed_file: str) -> ImpactReport:
        # Find all affected files
        affected_files = list(nx.descendants(self.graph, changed_file))
        
        # Calculate impact metrics
        impact_score = len(affected_files) / len(self.graph.nodes())
        risk_level = "high" if impact_score > 0.3 else "medium" if impact_score > 0.1 else "low"
        
        return ImpactReport(
            changed_file=changed_file,
            affected_files=affected_files,
            impact_score=impact_score,
            risk_level=risk_level
        )
```

### **✅ Caching Best Practices**
```python
# CORRECT - Multi-level caching with TTL and statistics
class GoodCacheManager:
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache: Dict[str, CacheEntry] = {}
        self.access_times: Dict[str, float] = {}
        self.hit_count = 0
        self.miss_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        if key not in self.cache:
            self.miss_count += 1
            return None
        
        entry = self.cache[key]
        if self._is_expired(entry):
            self._remove(key)
            self.miss_count += 1
            return None
        
        # Update access time for LRU
        self.access_times[key] = time.time()
        self.hit_count += 1
        return entry.value
    
    def set(self, key: str, value: Any) -> None:
        # Check size limit
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        # Store with TTL
        self.cache[key] = CacheEntry(value=value, created_at=time.time())
        self.access_times[key] = time.time()
    
    def get_stats(self) -> Dict[str, Any]:
        total_requests = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total_requests if total_requests > 0 else 0
        
        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "hit_rate": hit_rate,
            "ttl": self.ttl
        }
    
    def _is_expired(self, entry: CacheEntry) -> bool:
        return time.time() - entry.created_at > self.ttl
```

## 🧪 **TESTING ARCHITECTURE**

### **Unit Testing Pattern**
```python
def test_output_manager():
    """Test OutputManager with proper mocking."""
    # Mock dependencies
    mock_console_manager = Mock(spec=ConsoleManager)
    mock_formatter_registry = Mock(spec=FormatterRegistry)
    
    # Create OutputManager with mocked dependencies
    output_manager = OutputManager(
        console_manager=mock_console_manager,
        formatter_registry=mock_formatter_registry
    )
    
    # Test functionality
    result = output_manager.display(test_data, OutputFormat.TEXT)
    assert result is not None
```

### **Integration Testing Pattern**
```python
def test_cli_command_integration():
    """Test CLI command with real OutputManager."""
    # Use service factory (same as production)
    service_factory = get_service_factory()
    service = service_factory.create_service(test_config)
    
    # Test end-to-end functionality
    result = service.process()
    assert result is not None
```

## 📁 **FILE ORGANIZATION**

### **Output Module Structure**
```
src/repomap_tool/cli/output/
├── __init__.py                 # Public API exports
├── manager.py                  # OutputManager (main entry point)
├── console_manager.py          # Console management
├── protocols.py                # Formatter protocols and interfaces
├── formats.py                  # Output format definitions
├── standard_formatters.py      # Built-in formatters
├── template_formatter.py       # Template-based formatter
└── templates/                  # Template system
    ├── __init__.py
    ├── config.py               # Template configuration
    ├── engine.py               # Jinja2 template engine
    ├── loader.py               # Template loading
    ├── registry.py             # Template registry
    └── templates/              # Jinja2 template files
        ├── project_info.jinja2
        ├── search_response.jinja2
        ├── success.jinja2
        └── error.jinja2
```

## 🔄 **MIGRATION GUIDELINES**

### **From Legacy to New Architecture**

#### **Step 1: Replace Direct Console Usage**
```python
# OLD
console.print("Message")

# NEW
output_manager = get_output_manager()
output_manager.display_success("Message", ctx)
```

#### **Step 2: Use Service Factory**
```python
# OLD
service = SomeService(config)

# NEW
service_factory = get_service_factory()
service = service_factory.create_service(config)
```

#### **Step 3: Implement Formatters**
```python
# OLD
def display_data(data):
    print(f"Data: {data}")

# NEW
class DataFormatter(BaseFormatter):
    def format(self, data: Data, output_format: OutputFormat) -> str:
        return self._template_engine.render_template("data.jinja2", {"data": data})
```

## 🎯 **AI DEVELOPMENT QUALITY GATES**

### **AI Must Verify Before Completing Any Task**
- [ ] **ALL CLI commands use `OutputManager`** - AI must never use direct console.print
- [ ] **NO direct `console.print()` calls in CLI commands** - AI must use OutputManager
- [ ] **ALL services use constructor injection DI patterns** - AI must never instantiate services directly
- [ ] **NO direct service instantiation outside DI** - AI must use DI container
- [ ] **ALL constructors validate dependencies** - AI must raise errors for missing dependencies
- [ ] **ALL formatters implement `FormatterProtocol`** - AI must follow formatter interface
- [ ] **ALL output uses template system** - AI must use Jinja2 templates
- [ ] **ALL templates follow Jinja2 pattern standards** - AI must follow template patterns
- [ ] **ALL templates support configuration-driven rendering** - AI must use config.options
- [ ] **ALL templates provide emoji and non-emoji variants** - AI must support both
- [ ] **ALL matchers implement `MatcherProtocol` with caching** - AI must follow matcher interface
- [ ] **ALL matchers support multiple strategies** - AI must implement strategy pattern
- [ ] **ALL LLM optimizers use token budget management** - AI must respect token limits
- [ ] **ALL tree operations use session-based state management** - AI must use sessions
- [ ] **ALL dependency analysis uses graph-based representation** - AI must use NetworkX
- [ ] **ALL caching systems use TTL and size limits** - AI must implement proper caching
- [ ] **ALL code has comprehensive tests** - AI must maintain >80% test coverage
- [ ] **ALL code passes MyPy type checking** - AI must ensure type safety
- [ ] **ALL code follows existing patterns** - AI must not reinvent the wheel
- [ ] **ALL new features use existing DI container** - AI must not create new factories

### **Code Quality**
- [ ] Full MyPy compliance (no type errors)
- [ ] All data models use Pydantic
- [ ] Comprehensive test coverage (>80%)
- [ ] No DI linter violations
- [ ] All formatting and linting passes

### **Performance**
- [ ] Template rendering is efficient
- [ ] Console operations are batched where possible
- [ ] Memory usage is optimized
- [ ] No unnecessary object creation

## 🚀 **EXTENSIBILITY GUIDELINES**

### **Adding New Output Formats**
1. Add format to `OutputFormat` enum
2. Implement formatter in `standard_formatters.py`
3. Register formatter in `_register_default_formatters()`
4. Create template file if needed
5. Add tests for new format

### **Adding New Formatters**
1. Implement `FormatterProtocol` interface
2. Extend `BaseFormatter` for common functionality
3. Register in `FormatterRegistry`
4. Add comprehensive tests
5. Update documentation

### **Adding New Templates**
1. Create Jinja2 template file following the standard pattern:
   - Configuration-driven rendering (`config.options`)
   - Emoji and non-emoji variants
   - Hierarchical and flat layout support
   - Conditional sections for optional data
   - Consistent formatting and indentation
2. Register in `TemplateRegistry`
3. Test template rendering with various configurations
4. Document template variables and context structure
5. Add examples in documentation
6. Ensure template follows all pattern rules

### **Adding New Matching Strategies**
1. Implement strategy method in existing matcher class
2. Add strategy name to configurable strategies list
3. Ensure strategy returns consistent score format (0-100)
4. Add caching support for strategy results
5. Add comprehensive tests for new strategy
6. Document strategy behavior and use cases

### **Adding New LLM Optimization Strategies**
1. Implement new `SelectionStrategy` enum value
2. Add strategy implementation in `ContextSelector`
3. Ensure strategy respects token budget limits
4. Add strategy-specific configuration options
5. Test with various data sizes and token limits
6. Document strategy behavior and performance characteristics

### **Adding New Tree Operations**
1. Implement operation in `TreeManager` class
2. Ensure operation uses session-based state management
3. Add dependency-aware logic where appropriate
4. Implement proper error handling and validation
5. Add comprehensive tests for new operation
6. Update CLI commands to expose new operation

### **Adding New Dependency Analysis Features**
1. Implement feature using graph-based algorithms
2. Ensure feature integrates with existing `DependencyGraph`
3. Add centrality and impact analysis where relevant
4. Implement proper caching for expensive operations
5. Add comprehensive tests for new feature
6. Document feature behavior and performance implications

### **Adding New Caching Strategies**
1. Implement new cache strategy (LRU, LFU, etc.)
2. Ensure strategy supports TTL and size limits
3. Add cache statistics and monitoring
4. Implement proper eviction policies
5. Add comprehensive tests for new strategy
6. Document strategy behavior and performance characteristics

## 📋 **AI DEVELOPMENT WORKFLOW**

### **AI Must Follow This Workflow for Every Task**
1. **Read existing code patterns** - AI must understand current architecture
2. **Use existing DI container** - AI must not create new service factories
3. **Follow OutputManager pattern** - AI must never use direct console.print
4. **Implement proper error handling** - AI must use custom exception hierarchy
5. **Write comprehensive tests** - AI must maintain >80% test coverage
6. **Run CI pipeline** - AI must ensure `make ci-all` passes
7. **Verify all quality gates** - AI must check all compliance requirements
8. **Update documentation** - AI must document new patterns and changes

### **AI Development Checklist**
- [ ] **Read and understand existing patterns** before writing new code
- [ ] **Use existing DI container** for all service creation
- [ ] **Follow OutputManager pattern** for all CLI output
- [ ] **Implement proper error handling** with custom exceptions
- [ ] **Write comprehensive tests** for all new functionality
- [ ] **Run full CI pipeline** (`make ci-all`) before completing
- [ ] **Verify all quality gates** are met
- [ ] **Update documentation** for any new patterns
- [ ] **Follow existing naming conventions** and code style
- [ ] **Use existing protocols and interfaces** - don't create new ones
- [ ] **Implement proper caching** with TTL and statistics
- [ ] **Use existing template system** for all output formatting
- [ ] **Follow existing matcher patterns** for any new matching logic
- [ ] **Use existing tree exploration patterns** for any tree operations
- [ ] **Use existing dependency analysis patterns** for any graph operations

### **AI Must Never Do These Things**
- [ ] **Never instantiate services directly** - always use DI container
- [ ] **Never use direct console.print** - always use OutputManager
- [ ] **Never skip dependency validation** - always raise errors for missing dependencies
- [ ] **Never create new service factories** - always use existing DI container
- [ ] **Never bypass the template system** - always use Jinja2 templates
- [ ] **Never skip error handling** - always implement proper exception handling
- [ ] **Never skip tests** - always write comprehensive tests
- [ ] **Never ignore CI failures** - always fix all CI issues
- [ ] **Never create new protocols** - always use existing interfaces
- [ ] **Never skip caching** - always implement proper caching patterns

---

## 🤖 **AI DEVELOPMENT SUMMARY**

**For AI (Cursor):** These rules are your development guidelines. Follow them strictly to maintain code quality and architectural consistency.

### **Key AI Rules:**
1. **ALWAYS use dependency injection** - never instantiate services directly
2. **ALWAYS use OutputManager** - never use direct console.print in CLI commands
3. **ALWAYS validate dependencies** - raise errors for missing dependencies
4. **ALWAYS follow existing patterns** - don't reinvent the wheel
5. **ALWAYS write comprehensive tests** - maintain >80% test coverage
6. **ALWAYS run CI pipeline** - ensure `make ci-all` passes
7. **ALWAYS use existing DI container** - don't create new service factories
8. **ALWAYS follow template system** - use Jinja2 templates for output
9. **ALWAYS implement proper error handling** - use custom exception hierarchy
10. **ALWAYS follow existing protocols** - implement existing interfaces

### **AI Success Criteria:**
- ✅ All code follows existing architectural patterns
- ✅ All services use proper dependency injection
- ✅ All CLI output goes through OutputManager
- ✅ All code has comprehensive test coverage
- ✅ All code passes CI pipeline (`make ci-all`)
- ✅ All code follows type safety requirements
- ✅ All code follows existing naming conventions
- ✅ All new features integrate with existing systems

**Remember:** Consistency and adherence to existing patterns is more important than innovation. Follow these rules to maintain the high quality and architectural integrity of the RepoMap-Tool codebase.